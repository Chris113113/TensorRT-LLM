# --- Hugging Face Models ---
# These models are sourced from Hugging Face and follow the standard cache structure.
Qwen/Qwen2.5-VL-7B-Instruct
Qwen/Qwen3-30B-A3B
Qwen/Qwen3-32B-FP8
Qwen/Qwen3-32B
Qwen/Qwen3-4B
deepseek-ai/DeepSeek-R1
meta-llama/Llama-3.3-70B-Instruct
meta-llama/Llama-4-Maverick-17B-128E-Instruct

# --- Custom Quantized Models ---
# These models are not from Hugging Face and must be downloaded directly from their GCS path.
# They do not follow the standard Hugging Face cache structure.
gs://pirillo-sct-bucket/quantized_models/Qwen--Qwen3-32B_fp8_tp1/
gs://pirillo-sct-bucket/quantized_models/Qwen--Qwen3-32B_nvfp4_tp1/
gs://pirillo-sct-bucket/quantized_models/Qwen--Qwen3-4B_fp8_tp1/
gs://pirillo-sct-bucket/quantized_models/Qwen--Qwen3-4B_nvfp4_tp1/
gs://pirillo-sct-bucket/quantized_models/meta-llama--Llama-3.1-8B-Instruct_fp8_tp1/
gs://pirillo-sct-bucket/quantized_models/meta-llama--Llama-3.1-8B-Instruct_nvfp4_tp1/
gs://pirillo-sct-bucket/quantized_models/mistralai--Mixtral-8x7B-v0.1_fp8_tp1-huggingface/
gs://pirillo-sct-bucket/quantized_models/mistralai--Mixtral-8x7B-v0.1_fp8_tp1/
gs://pirillo-sct-bucket/quantized_models/mistralai--Mixtral-8x7B-v0.1_nvfp4_tp1-huggingface/
gs://pirillo-sct-bucket/quantized_models/mistralai--Mixtral-8x7B-v0.1_nvfp4_tp1/
gs://pirillo-sct-bucket/quantized_models/tensorrt_llm/meta-llama--Llama-3.1-8B-Instruct_fp8_tp1/
gs://pirillo-sct-bucket/quantized_models/tensorrt_llm/meta-llama--Llama-3.1-8B-Instruct_nvfp4_tp1/
gs://pirillo-sct-bucket/quantized_models/tensorrt_llm/meta-llama--Llama-3.3-70B-Instruct_fp8_tp1/
gs://pirillo-sct-bucket/quantized_models/tensorrt_llm/meta-llama--Llama-3.3-70B-Instruct_nvfp4_tp1/